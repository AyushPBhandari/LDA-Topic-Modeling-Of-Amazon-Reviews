{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Xiaomeng\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n",
      "C:\\Users\\Xiaomeng\\Anaconda3\\lib\\site-packages\\funcy\\colls.py:6: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import Mapping, Set, Iterable, Iterator, defaultdict\n",
      "C:\\Users\\Xiaomeng\\Anaconda3\\lib\\site-packages\\funcy\\colls.py:6: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import Mapping, Set, Iterable, Iterator, defaultdict\n",
      "C:\\Users\\Xiaomeng\\Anaconda3\\lib\\site-packages\\funcy\\flow.py:2: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated, and in 3.8 it will stop working\n",
      "  from collections import Hashable\n",
      "C:\\Users\\Xiaomeng\\Anaconda3\\lib\\site-packages\\nltk\\decorators.py:70: DeprecationWarning: `formatargspec` is deprecated since Python 3.5. Use `signature` and the `Signature` object directly\n",
      "  formatvalue=lambda value: \"\")[1:-1]\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pprint import pprint\n",
    "import pickle\n",
    "import numpy as np\n",
    "\n",
    "# Gensim\n",
    "import gensim\n",
    "from gensim import corpora\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "from gensim.models import ldamulticore\n",
    "#from gensim.parsing.preprocessing import STOPWORDS\n",
    "\n",
    "# spacy for lemmatization\n",
    "import spacy\n",
    "\n",
    "# Plotting tools\n",
    "import pyLDAvis\n",
    "import  pyLDAvis.gensim # don't skip this\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "\n",
    "import nltk\n",
    "\n",
    "# Enable logging for gensim - optional\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.ERROR)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\",category=DeprecationWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\Xiaomeng\\\\OneDrive\\\\Project\\\\Category Dataframe'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "cwd = os.getcwd()\n",
    "data_dir = os.path.join(cwd,'Category Dataframe')\n",
    "os.chdir(data_dir)\n",
    "data_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save train and test data index in to pickle\n",
    "f =open('data_lemmatized.pkl','rb')\n",
    "data_lemmatized =pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[(4, 1), (14, 1), (43, 1), (60, 1), (119, 1), (659, 1), (1366, 1), (9780, 1), (22959, 1), (22960, 1), (22961, 1)]]\n",
      "[[(43, 1), (322, 1), (408, 1), (419, 1), (435, 2), (554, 1), (954, 1), (1127, 1), (2243, 2), (3245, 1), (4325, 2), (5030, 1), (7567, 1)]]\n",
      "9644\n",
      "104400\n"
     ]
    }
   ],
   "source": [
    "# Create Dictionary\n",
    "id2word = corpora.Dictionary(data_lemmatized)\n",
    "\n",
    "# Create Corpus\n",
    "texts = data_lemmatized\n",
    "\n",
    "# Term Document Frequency\n",
    "corpus = [id2word.doc2bow(text) for text in texts]\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "corpus_index = [i for i in range(len(corpus))]\n",
    "\n",
    "train, test, train_index, test_index = train_test_split(corpus, corpus_index, test_size=0.33, random_state=42)\n",
    "print(train[:1])\n",
    "print(test[:1])\n",
    "print(train_index[0])\n",
    "print(test_index[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find optimal number of topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_metrics(dictionary,train,test,texts,n_list):\n",
    "    \"\"\"\n",
    "    Compute c_v coherence for various number of topics\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    dictionary : Gensim dictionary\n",
    "    corpus : Gensim corpus\n",
    "    texts : List of input texts\n",
    "    limit : Max num of topics\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    model_list : List of LDA topic models\n",
    "    coherence_values : Coherence values corresponding to the LDA model with respective number of topics\n",
    "    \"\"\"\n",
    "    from gensim.models.coherencemodel import CoherenceModel\n",
    "    coherence_values = []\n",
    "    model_list = []\n",
    "    perplexity_values = []\n",
    "    for num_topics in n_list:\n",
    "        t0 = time()\n",
    "        \n",
    "        print('================================ N_topics %f =====================================' %num_topics)\n",
    "        filename = 'model_n_{0}.sav'.format(num_topics)\n",
    "        model = pickle.load(open(filename, 'rb'))\n",
    "        \n",
    "        model_list.append(model)\n",
    "        # Compute Coherence Score\n",
    "        coherence_model = CoherenceModel(model = model, corpus=test,texts=data_lemmatized, dictionary=dictionary, coherence='c_npmi')\n",
    "        coherence = coherence_model.get_coherence()\n",
    "        coherence_values.append(coherence)\n",
    "        \n",
    "        print('Coherence Score:test=%.3f' %coherence)\n",
    "        \n",
    "        # Compute Perplexity \n",
    "        #perplexity = model.log_perplexity(test)\n",
    "        #print('preplexity: test=%.3f' %perplexity)\n",
    "        #perplexity_values.append(perplexity)\n",
    "        \n",
    "              \n",
    "        print(\"done in %0.3fs.\" %(time() - t0))\n",
    "    return model_list, coherence_values,perplexity_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'model_n_{0}.sav'.format(5)\n",
    "model = pickle.load(open(filename, 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'compute_metrics' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-d25861117f86>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtime\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mn_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m25\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m30\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m40\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m50\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m60\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m70\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m80\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mmodel_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcoherence_values\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mperplexity_values\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcompute_metrics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdictionary\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mid2word\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtexts\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata_lemmatized\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mn_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'compute_metrics' is not defined"
     ]
    }
   ],
   "source": [
    "# Can take a long time to run.\n",
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "from time import time\n",
    "n_list = [5,10,15,20,25,30,40,50,60,70,80]\n",
    "model_list, coherence_values, perplexity_values = compute_metrics(dictionary=id2word, train=train, test = test,texts=data_lemmatized, n_list = n_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================ N_topics 5.000000 =====================================\n",
      "Cv Score:test=0.307\n",
      "done in 8.978s.\n",
      "================================ N_topics 10.000000 =====================================\n",
      "Cv Score:test=0.343\n",
      "done in 11.502s.\n",
      "================================ N_topics 15.000000 =====================================\n",
      "Cv Score:test=0.384\n",
      "done in 20.277s.\n",
      "================================ N_topics 20.000000 =====================================\n",
      "Cv Score:test=0.361\n",
      "done in 28.322s.\n",
      "================================ N_topics 25.000000 =====================================\n",
      "Cv Score:test=0.405\n",
      "done in 27.065s.\n",
      "================================ N_topics 30.000000 =====================================\n",
      "Cv Score:test=0.406\n",
      "done in 28.992s.\n",
      "================================ N_topics 40.000000 =====================================\n",
      "Cv Score:test=0.443\n",
      "done in 35.717s.\n",
      "================================ N_topics 50.000000 =====================================\n",
      "Cv Score:test=0.436\n",
      "done in 48.130s.\n",
      "================================ N_topics 60.000000 =====================================\n",
      "Cv Score:test=0.465\n",
      "done in 57.865s.\n",
      "================================ N_topics 70.000000 =====================================\n",
      "Cv Score:test=0.468\n",
      "done in 71.341s.\n",
      "================================ N_topics 80.000000 =====================================\n",
      "Cv Score:test=0.481\n",
      "done in 83.563s.\n",
      "================================ N_topics 90.000000 =====================================\n",
      "Cv Score:test=0.492\n",
      "done in 104.971s.\n"
     ]
    }
   ],
   "source": [
    "cv_values = []\n",
    "n_list = [5,10,15,20,25,30,40,50,60,70,80,90]\n",
    "for num_topics in n_list:\n",
    "    t0 = time()\n",
    "    print('================================ N_topics %f =====================================' %num_topics)\n",
    "    filename = 'model_n_{0}.sav'.format(num_topics)\n",
    "    model = pickle.load(open(filename, 'rb'))\n",
    "    coherence_model = CoherenceModel(model = model,texts=data_lemmatized, dictionary=id2word, coherence='c_v')\n",
    "    cv = coherence_model.get_coherence()\n",
    "    cv_values.append(cv)\n",
    "    print('Cv Score:test=%.3f' %cv)\n",
    "    print(\"done in %0.3fs.\" %(time() - t0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show graph\n",
    "x = [5,10,15,20,25,30,40,50,60,70,80]\n",
    "plt.plot(x, coherence_values[:11])\n",
    "plt.xlabel(\"Num Topics\")\n",
    "plt.ylabel(\"Coherence score:c\")\n",
    "plt.legend((\"coherence_values\"), loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Show graph\n",
    "\n",
    "x = [5,10,15,20,25,30,40,50,60,70,80,90]\n",
    "plt.plot(x, cv_values)\n",
    "plt.xlabel(\"Num Topics\")\n",
    "plt.ylabel(\"Coherence score:cv\")\n",
    "plt.legend((\"coherence_values\"), loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the coherence scores\n",
    "for m, cv in zip(x, coherence_values):\n",
    "    print(\"Num Topics =\", m, \" has Coherence Value of\", round(cv, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build LDA model\n",
    "lda_model = gensim.models.ldamodel.LdaModel(corpus=train,\n",
    "                                           id2word=id2word,\n",
    "                                           num_topics=30, \n",
    "                                           random_state=100,\n",
    "                                           update_every=1,\n",
    "                                           chunksize=100,\n",
    "                                           passes=10,\n",
    "                                           alpha='auto',\n",
    "                                           per_word_topics=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model.save(\"lda_model_gensim\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the Keyword in the 10 topics\n",
    "pprint(lda_model.print_topics(30))\n",
    "doc_lda = lda_model[test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Perplexity\n",
    "print('\\nPerplexity: ', lda_model.log_perplexity(corpus))  # a measure of how good the model is. lower the better.\n",
    "\n",
    "# Compute Coherence Score\n",
    "coherence_model_lda = CoherenceModel(model=lda_model, texts=data_lemmatized, dictionary=id2word, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta, _ = lda_model.inference(train)\n",
    "theta /= theta.sum(axis=1)[:, None]\n",
    "theta_df_train = pd.DataFrame(theta)\n",
    "\n",
    "theta, _ = lda_model.inference(test)\n",
    "theta /= theta.sum(axis=1)[:, None]\n",
    "theta_df_test = pd.DataFrame(theta)\n",
    "\n",
    "\n",
    "from sklearn import svm\n",
    "x = theta_df_train\n",
    "y = list(all_data_df.iloc[train_index]['category'])\n",
    "\n",
    "clf = svm.LinearSVC()\n",
    "clf.fit(x,y)\n",
    "result = clf.predict(theta_df_test)\n",
    "\n",
    "i = 0\n",
    "for y,y_pred in zip(all_data_df.iloc[test_index]['category'],result):\n",
    "    if y == y_pred:\n",
    "        i +=1\n",
    "        \n",
    "print(i/len(result)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE \n",
    "tsne = TSNE(n_components=2, perplexity=50)\n",
    "\n",
    "# TSNE is taking too long for bigger dataset\n",
    "#reduced_X = theta_df_test.sample(n=5000)\n",
    "tsne_data = tsne.fit_transform(theta_df_test)\n",
    "tsne_data = pd.DataFrame(tsne_data, columns=[\"dim1\", \"dim2\"])\n",
    "tsne_data.plot(\"dim1\", \"dim2\", kind=\"scatter\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pyLDAvis.gensim\n",
    "pyLDAvis.enable_notebook()\n",
    "vis = pyLDAvis.gensim.prepare(lda_model, corpus, dct,mds='tsne',sort_topics=False)\n",
    "pyLDAvis.display(vis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyLDAvis.save_html(vis, 'lda.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Select the model and print the topics\n",
    "optimal_model = model_list[3]\n",
    "model_topics = optimal_model.show_topics(formatted=False)\n",
    "pprint(optimal_model.print_topics(num_words=10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# t - sne Visulization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta, _ = lda_model_2.inference(train)\n",
    "theta /= theta.sum(axis=1)[:, None]\n",
    "theta_df_train = pd.DataFrame(theta)\n",
    "\n",
    "theta, _ = lda_model_2.inference(test)\n",
    "theta /= theta.sum(axis=1)[:, None]\n",
    "theta_df_test = pd.DataFrame(theta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "x = theta_df_train\n",
    "y = list(all_data_df.iloc[train_index]['category'])\n",
    "\n",
    "clf = svm.LinearSVC()\n",
    "clf.fit(x,y)\n",
    "result = clf.predict(theta_df_test)\n",
    "\n",
    "i = 0\n",
    "for y,y_pred in zip(all_data_df.iloc[test_index]['category'],result):\n",
    "    if y == y_pred:\n",
    "        i +=1\n",
    "        \n",
    "print(i/len(result)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building LDA Mallet Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from gensim.models.wrappers import LdaMallet\n",
    "os.environ.update({'MALLET_HOME':r'C:/Xiaomeng/mallet/'})\n",
    "mallet_path = 'C:\\\\Xiaomeng\\\\mallet\\\\bin\\\\mallet' # update this path\n",
    "\n",
    "#ldamallet = gensim.models.wrappers.LdaMallet(mallet_path, corpus=corpus, num_topics=3, id2word=id2word)\n",
    "\n",
    "#result = (ldamallet.show_topics(num_topics=3, num_words=10,formatted=False))\n",
    "#for each in result:\n",
    "#print (each)\n",
    "#os.environ['MALLET_HOME'] = 'C:/Users/Xiaomeng/OneDrive/Project/Category Dataframe/mallet'\n",
    "#mallet_path = 'C:/Users/Xiaomeng/OneDrive/Project/Category Dataframe/mallet/bin/mallet' # update this path\n",
    "#mallet_path = 'C:\\Users\\Xiaomeng\\OneDrive\\Project\\Category Dataframe\\mallet\\bin\\mallet' # update this path\n",
    "ldamallet = LdaMallet(mallet_path, corpus=train, num_topics=30, id2word=id2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show Topics\n",
    "pprint(ldamallet.show_topics(formatted=False))\n",
    "\n",
    "# Compute Coherence Score\n",
    "coherence_model_ldamallet = CoherenceModel(model=ldamallet, texts=data_lemmatized, dictionary=id2word, coherence='c_v')\n",
    "coherence_ldamallet = coherence_model_ldamallet.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_ldamallet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_coherence_values(dictionary, corpus, texts, limit, start=2, step=3):\n",
    "    \"\"\"\n",
    "    Compute c_v coherence for various number of topics\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    dictionary : Gensim dictionary\n",
    "    corpus : Gensim corpus\n",
    "    texts : List of input texts\n",
    "    limit : Max num of topics\n",
    "\n",
    "    Returns:\n",
    "    -------\n",
    "    model_list : List of LDA topic models\n",
    "    coherence_values : Coherence values corresponding to the LDA model with respective number of topics\n",
    "    \"\"\"\n",
    "    coherence_values = []\n",
    "    model_list = []\n",
    "    for num_topics in range(start, limit, step):\n",
    "        model = gensim.models.wrappers.LdaMallet(mallet_path, corpus=corpus, num_topics=num_topics, id2word=id2word)\n",
    "        model_list.append(model)\n",
    "        coherencemodel = CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
    "        coherence_values.append(coherencemodel.get_coherence())\n",
    "\n",
    "    return model_list, coherence_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mode"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Can take a long time to run.\n",
    "model_list, coherence_values = compute_coherence_values(dictionary=dct, corpus=corpus, texts=data_lemmatized, start=2, limit=40, step=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build LDA model with the result from hyperparameter tuning\n",
    "lda_model_2 = gensim.models.LdaMulticore(corpus=train,\n",
    "                                           id2word=id2word,\n",
    "                                           num_topics=30, \n",
    "                                           random_state=100,\n",
    "                                           chunksize=100,\n",
    "                                           passes=10,\n",
    "                                           alpha=0.6,\n",
    "                                            eta=0.05,\n",
    "                                           per_word_topics=True)\n",
    "\n",
    "lda_model_2.save(\"lda_model2_gensim\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model_2 = gensim.models.LdaModel.load(\"lda_model2_gensim\")\n",
    "theta, _ = lda_model_2.inference(train)\n",
    "theta /= theta.sum(axis=1)[:, None]\n",
    "theta_df_test = pd.DataFrame(theta)\n",
    "tsne = TSNE(n_components=2, perplexity=50)\n",
    "\n",
    "# Clean and sample the data from each categories\n",
    "#theta_df_clean = theta_df[ theta_df['category'] != \"\" ]\n",
    "#theta_df_grouped = theta_df_clean.groupby(['category'])\n",
    "#theta_df_grouped = theta_df_grouped.apply(lambda x: x.sample(frac=0.3))\n",
    "# TSNE is taking too long for bigger dataset\n",
    "reduced_X = theta_df_grouped.sample(n=6000)\n",
    "\n",
    "\n",
    "tsne_data = tsne.fit_transform(reduced_X.ix[:, :30])\n",
    "tsne_data = pd.DataFrame(tsne_data, columns=[\"dim1\", \"dim2\"])\n",
    "tsne_data.plot(\"dim1\", \"dim2\", kind=\"scatter\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tsne_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # label_marker dictionary for true labels\n",
    "    unqique_label = np.unique(result_df['labels_predict'].tolist())\n",
    "    unqique_true_label = np.unique(result_df['label'].tolist())\n",
    "    markers = ['o','*','s']\n",
    "    keys = [str(x) for x in unqique_true_label]\n",
    "    true_label_dict = dict(zip(keys, markers))\n",
    "    \n",
    "    for k in unqique_predict_label:\n",
    "        result_df.loc[(result_df['labels_predict']== k),'color'] = label_dict[str(int(k))]\n",
    "            \n",
    "    for kt in unqique_true_label:\n",
    "        result_df.loc[(result_df['label']== kt),'marker'] = true_label_dict[str(kt)]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Perplexity\n",
    "print('\\nPerplexity: ', lda_model_2.log_perplexity(corpus))  # a measure of how good the model is. lower the better.\n",
    "\n",
    "# Compute Coherence Score\n",
    "coherence_model_lda = CoherenceModel(model=lda_model_2, corpus=test,texts=data_lemmatized, dictionary=id2word, coherence='c_npmi')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tsne_data['label'] = list(theta_df_test['category'])\n",
    "from ggplot import *\n",
    "ggplot(tsne_data, aes(x='dim1', y='dim2', color='category')) +\\\n",
    "    geom_point()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
